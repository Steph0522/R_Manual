# Introducción a la estadística


##	Diferencia entre estadística y bioestadística
##	Estadística descriptiva: medidas de tendencia central y medidas de dispersión
##	Estadística inferencial: Univariada y multivariada
##	Estadística inferencial paramétrica: supuestos principales de las pruebas paramétricas

Se conoce como estadística paramétrica a aquella que se basa en el muestreo de una población con una distribución conocida y con  parámetros fijos. 

Los supuestos de las pruebas paramétricas en general son:

- Distribución conocida (**normal**): visual y pruebas numéricas.

- Homocedasticidad: visual y pruebas numéricas.

- Otros: tamaño de la muestra, variables cuantitativas o continuas, outliers, aleatoriedad, independencia de las observaciones, linealidad. 

##	¿Cómo saber si mis datos presentan una distribución normal y homogeneidad de las variancias?:

### Métodos visuales
```{r}
set.seed(123)
data_normal<- rnorm(200)
hist(data_normal, col='steelblue', main='Normal')
data_no_normal<- rexp(100, rate=3)
hist(data_no_normal, col='red', main='No normal')
```


```{r}
plot(density(data_normal), main="Normal")
plot(density(data_no_normal), main="No Normal")

```



```{r}
qqnorm(data_normal)
qqline(data_normal)
```


```{r}
qqnorm(data_no_normal)
qqline(data_no_normal)
```


###	Prueba de Shapiro-Wilk

```{r}
shapiro.test(data_normal)

```

```{r}
shapiro.test(data_no_normal)
```


###	Pruebas de ajuste o distribución: Prueba de Kolmogorov-Smirnov, Prueba de Anderson-Darling

```{r}
ks.test(data_normal, "pnorm")

```


```{r}
ks.test(data_no_normal, "pnorm")

```


###	Probando Homocedasticidad o heterocedasticidad

```{r, fig.align='center', fig.height=5,fig.width=4, message=FALSE, warning=FALSE}
aggregate(len ~ supp, data = ToothGrowth, var)
```

Ratio
```{r}
68.32 /  43.63
```


```{r, fig.align='center', fig.height=5,fig.width=4, message=FALSE, warning=FALSE}
aggregate(Petal.Width ~ Species, data = iris, var)

```
Ratio
```{r}
r1<-0.03910612 / 0.01110612 #versicolor vs setosa
r2<-0.07543265 / 0.01110612 #virginca vs setosa
r3<-0.07543264 / 0.03910612 #virginica vs versicolor
cbind(r1,r2,r3)
```

```{r, fig.align='center', fig.height=5,fig.width=8, message=FALSE, warning=FALSE}
m1<-lm(len ~ supp, data=ToothGrowth)
par(mfrow = c(1, 2))
plot(m1, which=c(1,3))
```



```{r, fig.align='center', fig.height=5,fig.width=8, message=FALSE, warning=FALSE}
m2<-lm(Petal.Width ~ Species, data=iris)
par(mfrow = c(1, 2))
plot(m2, which=c(1,3))
```


Prueba para dos niveles = F

```{r, fig.align='center', fig.height=5,fig.width=8, message=FALSE, warning=FALSE}

var.test(len ~ supp, data = ToothGrowth) 

```

```{r, fig.align='center', fig.height=5,fig.width=8, message=FALSE, warning=FALSE}
lmtest::bptest(m2) #sobre un modelo

```


#### Otras pruebas


```{r}
GAD::C.test(m2)
```


```{r}
car::leveneTest(m2)
```


**Ejemplo:**

```{r}
data(iris)
cols<- c("Largo_Sepalo", "Ancho_Sepalo", "Largo_Petalo", "Ancho_Petalo", "Especies")
colnames(iris)<- cols
```

Este conjunto de datos describe tres especies de las flores iris y como cambia el ancho y largo de su pétalo y sépalo.
Veamos la estructura de los datos:

```{r}
str(iris)
dim(iris)
nrow(iris)
ncol(iris)
```

Como vemos, posee 4 variables de respuesta y un factor que sería la especie de flor.


- Explorando normalidad en los datos

Existen diversas gráficas que podemos realizar para probar o explorar si nuestros datos siguen una distribución normal (también llamada distribución gaussiana) y su gráfica debe tener una forma acampanada y simétrica.
La aplicación de muchas pruebas y estadísticos depende de si los datos siguen esta distribución o no.
Por esto es importante antes de aplicar cualquier prueba estadística, explorar la distribución de nuestros datos y sí la prueba o estadístico que aplicamos asume que nuestros datos sean normales o no.
Para este ejemplo, usaremos el ancho del sepalo en vez del largo del sepalo.
¨

\

```{r}
hist(iris$Ancho_Sepalo)
plot(density(iris$Ancho_Sepalo))

```

```{r}
qqnorm(iris$Ancho_Sepalo)
qqline(iris$Ancho_Sepalo)
```

```{r, warning=FALSE, message=FALSE}
library(car) # cargamos el paquete car
qqPlot(iris$Ancho_Sepalo )
```

Al parecer nuestros datos tienen una distribución normal, según los gráficos, sin embargo, para estar seguros de esto, haremos una prueba llamada test de shapiro que nos permitirá confirmar esto:\

```{r}
shapiro.test(iris$Ancho_Sepalo)
```

\

La hipótesis nula que estamos aceptando o rechazando con esta prueba es que la distribución es normal y escogiendo un valor de probabilidad de 0.05 y dado que 0.1012 \> 0.05 no podemos rechazar la hipótesis nula.
En caso que este valor de p-value \< 0.05 entonces los datos no serían normales.


##	Estadística inferencial no paramétrica: supuestos principales de las pruebas no paramétricas

